{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6826729921972381734, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11323454260\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 2787711032108987066\n",
       " physical_device_desc: \"device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "dataf_name = \"data.csv\"\n",
    "\n",
    "log_dir = \"logs\"\n",
    "result_dir = \"results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain audio file names and tempos from a csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio files and the csv file are expected to be in the directory `data/`,  \n",
    "and the csv file is expected to have the names of the audio file in the first column,  \n",
    "and the tempos corresponding audio files in the second column,  \n",
    "with no header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepend directory to dataf_name if not present\n",
    "dataf_name = data_dir + '/' + dataf_name if dataf_name.split('/')[0] != data_dir else dataf_name\n",
    "\n",
    "audiofs = np.genfromtxt(dataf_name, delimiter=',', dtype='unicode')\n",
    "# prepend directory to track names if not present\n",
    "audiof_names = [data_dir + '/' + audiof_name if audiof_name.split('/')[0] != data_dir\n",
    "                else audiof_name\n",
    "                for audiof_name in audiofs[:, 0]]\n",
    "# append file extension (.wav) to track names if not present\n",
    "audiof_names = [audiof_name + \".wav\" if audiof_name.split('.')[-1] != \"wav\"\n",
    "                else audiof_name\n",
    "                for audiof_name in audiof_names]\n",
    "audiofs = np.stack((audiof_names, audiofs[:,1]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import stft, istft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msl012/Project/msl012/local/lib/python3.5/site-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr import_audio\n",
    "samp_rate = 44100 # treat processed data as if sampled at 44.1 kHz\n",
    "mid_tempo = int(np.median(audiofs[:,1].astype(int))) # median tempo of dataset\n",
    "samp_per_beat = int(60*samp_rate/mid_tempo) # (60sec/min)*(Hz/bpm) = cycle/beat\n",
    "\n",
    "clips = []\n",
    "for [audiof_name, tempo] in audiofs:\n",
    "    rate, audiof = wavfile.read(audiof_name)\n",
    "    \n",
    "    # convert stereo to mono\n",
    "    if audiof.shape[1] == 2:\n",
    "        # type conversions to minimize risk of overflow\n",
    "        audiof = (audiof.astype(int).sum(axis=1) // 2).astype(int)\n",
    "        \n",
    "    tempo = int(tempo) # cast from string\n",
    "    # normalize tempo to the median of dataset\n",
    "    if tempo != mid_tempo:\n",
    "        audio_length = audiof.shape[0] / rate\n",
    "        intervals_old = np.linspace(0, audio_length, audiof.shape[0])\n",
    "        intervals_new = np.linspace(0, audio_length, int(audiof.shape[0]*tempo/mid_tempo))\n",
    "        # construct interpolation and resample\n",
    "        audiof = (interp1d(intervals_old, audiof)(intervals_new)).astype(int)\n",
    "        \n",
    "    # produce up to 5 different random 16-beat clips from audiof\n",
    "    num_clips = 5\n",
    "    len_clip = 16*samp_per_beat\n",
    "    max_num_clips = int(audiof.shape[0]/len_clip)\n",
    "    # array containing starting indices of clips\n",
    "    pos_clips = (np.random.choice(max_num_clips,\n",
    "                                  size=min(max_num_clips, num_clips),\n",
    "                                  replace=False)\n",
    "                 *len_clip).astype(int)\n",
    "    for index_clip, pos_clip in enumerate(pos_clips):\n",
    "        clip = audiof[pos_clip:pos_clip+len_clip]\n",
    "        # write clip for potential debugging\n",
    "        wavfile.write(\"clips/{}{}.wav\".format(audiof_name.split('/')[-1].split('.')[0], index_clip), samp_rate, clip)\n",
    "        # apply short-time Fourier transform to clip's PCM\n",
    "        transformed = stft(clip)[2].T\n",
    "        # separate real and imag components and concatenate\n",
    "        transformed = np.concatenate((transformed.real, transformed.imag), axis=1)\n",
    "        clips.append(transformed)\n",
    "    print(\"Imported \" + audiof_name)\n",
    "\n",
    "# convert list to numpy array and shuffle order of clips\n",
    "clips = np.array(clips)\n",
    "np.random.shuffle(clips)\n",
    "\n",
    "# normalize data\n",
    "clips_means = np.mean(clips, axis=0)\n",
    "clips_deviations = np.std(clips, axis=0)\n",
    "clips = np.nan_to_num((clips - clips_means) / clips_deviations)\n",
    "\n",
    "%store clips_means\n",
    "%store clips_deviations\n",
    "%store clips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the `true_divide` `RuntimeWarning`; it's handled with `np.nan_to_num()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"{}/import_audio\".format(log_dir), 'w') as log:\n",
    "    log.write(import_audio.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(num_samples, num_timesteps, num_features) = clips.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Keras Implementaion for Proof of Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = clips\n",
    "y = np.roll(clips, -1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(2048, input_shape=(None, num_features), return_sequences=True, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(1024, return_sequences=True, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(num_features)))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr fit\n",
    "history = model.fit(X, y, batch_size=1, epochs=100)\n",
    "model.save(\"{}/model.h5\".format(result_dir))\n",
    "%store history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"{}/fit\".format(log_dir), 'w') as log:\n",
    "    log.write(fit.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_audio(model, seed, length):\n",
    "    prediction = seed\n",
    "    output = np.zeros((1, length, len(seed)))\n",
    "    for i in range(length):\n",
    "        output[0, i] = prediction\n",
    "        prediction = model.predict(output[:, :i+1, :])[0][-1]\n",
    "        print(\"{}/{}\".format(i+1, length), end=\"\\r\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr generate\n",
    "# select random timestep from random sample as seed\n",
    "seed = clips[np.random.randint(num_samples), np.random.randint(num_timesteps)] # I should add a bit of noise, too\n",
    "result_transformed = generate_audio(model, seed, num_timesteps)\n",
    "# denormalize data\n",
    "result_denormalized = (result_transformed * clips_deviations) + clips_means\n",
    "%store result_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"{}/generate\".format(log_dir), 'w') as log:\n",
    "    log.write(generate.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(real, imag) = np.split(result_denormalized[0], 2, axis=1)\n",
    "result = istft((real + 1j*imag).T)[1].round().astype(np.int16)\n",
    "%store result\n",
    "wavfile.write(\"{}/result.wav\".format(result_dir), samp_rate, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%store -r\n",
    "from keras.models import load_model\n",
    "\n",
    "clips_means\n",
    "clips_deviations\n",
    "clips\n",
    "model = load_model(\"{}/model.h5\".format(result_dir))\n",
    "history\n",
    "result_transformed\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# could the \"music\" generated be attributable to the denormalization process?\n",
    "result_min = result_transformed.min()\n",
    "result_max = result_transformed.max()\n",
    "result_range = result_max - result_min\n",
    "rand_transformed = (np.random.random(result_transformed.shape) * result_range) + result_min\n",
    "\n",
    "rand_denormalized = (rand_transformed * clips_deviations) + clips_means\n",
    "\n",
    "(rand_real, rand_imag) = np.split(rand_denormalized[0], 2, axis=1)\n",
    "rand_result = istft((rand_real + 1j*rand_imag).T)[1].round().astype(np.int16)\n",
    "\n",
    "wavfile.write(\"{}/rand_result.wav\".format(result_dir), samp_rate, rand_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
